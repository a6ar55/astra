MODEL COMPARISON: DistilBERT vs RoBERTa PEFT
=========================================

TEST DATASET
-----------
File: 111.csv
Samples: 755
Classes: 5 threat categories (Child Safety Threats, Criminal Activity, Direct Violence Threats, Harassment and Intimidation, Hate Speech/Extremism)

MODELS OVERVIEW
-------------
1. DistilBERT (models/best_model)
   - Successfully evaluated on the test dataset
   - Production-ready performance
   
2. RoBERTa PEFT LoRA (models/roberta_peft_lora)
   - Not successfully evaluated due to model loading issues
   - Architecture mismatch between base model and adapter weights
   - The base model has a classification head with 16 outputs, but our adapter is configured for 6 classes
   - Most likely the model wasn't properly trained or saved with the correct configuration

DISTILBERT PERFORMANCE
--------------------
Accuracy:  0.9669 (96.69%)
Precision: 0.9697 (96.97%)
Recall:    0.9669 (96.69%)
F1 Score:  0.9662 (96.62%)
Inference time: 0.0226s per sample

Per-Class Performance:
1. Child Safety Threats:        F1 = 0.9733, Precision = 1.0000, Recall = 0.9479
2. Criminal Activity:           F1 = 0.9844, Precision = 0.9693, Recall = 1.0000
3. Direct Violence Threats:     F1 = 0.9020, Precision = 1.0000, Recall = 0.8214
4. Harassment and Intimidation: F1 = 0.9487, Precision = 0.9024, Recall = 1.0000
5. Hate Speech/Extremism:       F1 = 1.0000, Precision = 1.0000, Recall = 1.0000

ROBERTA PEFT PERFORMANCE
----------------------
The RoBERTa PEFT model could not be evaluated due to technical issues:
- Error loading the model: size mismatch between the classifier head dimensions
- Base model has 16 outputs in classification layer, adapter model was configured for 6 classes
- This indicates a potential issue with how the model was trained or saved

ERROR ANALYSIS FOR DISTILBERT
---------------------------
- Overall error rate: 3.31% (25 incorrect predictions out of 755)
- Main error pattern: confusion between "Direct Violence Threats" and "Harassment and Intimidation" categories
- 20 out of 112 Direct Violence Threats were incorrectly classified as Harassment and Intimidation
- Perfect performance on Hate Speech/Extremism category (100% F1 score)

CONFIDENCE ANALYSIS FOR DISTILBERT
-------------------------------
- Average confidence: 98.81%
- Average confidence when correct: 99.27%
- Average confidence when incorrect: 85.53%
- The model has high confidence overall, with lower confidence on incorrectly classified examples

CONCLUSION
---------
1. DistilBERT Performance:
   - Excellent performance with 96.69% accuracy and 96.62% F1-score
   - Very good inference speed (0.0226s per sample)
   - Perfect performance on Hate Speech/Extremism category
   - Main confusion is between Direct Violence Threats and Harassment categories

2. RoBERTa PEFT:
   - Could not be evaluated due to model loading issues
   - The model likely wasn't properly trained or saved with the correct configuration
   - Architecture mismatch between the base model (16 classes) and our classification task (6 classes)

3. Recommendation:
   - Use the DistilBERT model for production deployment
   - It shows strong performance across all five threat categories
   - Re-train the RoBERTa PEFT model with correct configuration if needed
   - DistilBERT is already highly accurate and efficient for the threat detection task 